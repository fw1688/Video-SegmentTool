import cv2
import torch
import numpy as np
from torchvision import transforms
import torch.nn.functional as F
from PIL import Image
import os
from pathlib import Path
import json
from typing import List, Tuple, Dict
import logging
from collections import deque
import time
from datetime import datetime

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('video_segmentation.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class GameVideoSegmenter:
    def __init__(self, device='cuda' if torch.cuda.is_available() else 'cpu'):
        self.device = device
        self._check_gpu_status()
        self.setup_models()
        self.setup_transforms()

        # æå¤§é™ä½é˜ˆå€¼ï¼Œæé«˜å¥½å¸§é‡‡æ ·ç‡
        self.motion_threshold = 0.01  # å¤§å¹…é™ä½è¿åŠ¨é˜ˆå€¼
        self.brightness_threshold = 15  # å¤§å¹…é™ä½äº®åº¦é˜ˆå€¼
        self.sharpness_threshold = 10  # å¤§å¹…é™ä½æ¸…æ™°åº¦é˜ˆå€¼
        self.mouse_movement_threshold = 0.3  # æé«˜é¼ æ ‡ç§»åŠ¨é˜ˆå€¼ï¼Œæ›´å®½å®¹

        # åˆ†æ®µå‚æ•°
        self.min_segment_duration = 1.0  # æœ€å°åˆ†æ®µæ—¶é•¿(ç§’)
        self.max_gap_duration = 0.5  # æœ€å¤§å®¹å¿é—´éš”(ç§’)
        self.stable_frames_threshold = 10  # ç¨³å®šå¸§æ•°é˜ˆå€¼

        # çŠ¶æ€å˜é‡
        self.frame_buffer = deque(maxlen=5)
        self.good_frames_count = 0
        self.bad_frames_count = 0
        self.current_segment_start = None

    def _check_gpu_status(self):
        """æ£€æŸ¥GPUçŠ¶æ€å’Œæ€§èƒ½"""
        logger.info("=== GPU/CPU è®¾å¤‡çŠ¶æ€æ£€æŸ¥ ===")

        if torch.cuda.is_available():
            logger.info(f"âœ… CUDAå¯ç”¨ï¼Œä½¿ç”¨è®¾å¤‡: {self.device}")
            gpu_count = torch.cuda.device_count()
            logger.info(f"ğŸ“Š æ£€æµ‹åˆ° {gpu_count} ä¸ªGPUè®¾å¤‡")
            for i in range(gpu_count):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / (1024 ** 3)
                logger.info(f"  GPU {i}: {gpu_name}, æ˜¾å­˜: {gpu_memory:.1f}GB")
        else:
            logger.warning("âŒ CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUè¿›è¡Œè®¡ç®—")

        logger.info("=== è®¾å¤‡æ£€æŸ¥å®Œæˆ ===\n")

    def setup_models(self):
        """è®¾ç½®éœ€è¦çš„æ¨¡å‹"""
        logger.info("æ­£åœ¨åŠ è½½AIæ¨¡å‹...")
        try:
            # åŠ è½½ç›®æ ‡æ£€æµ‹æ¨¡å‹ç”¨äºUIå…ƒç´ æ£€æµ‹
            self.detection_model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)
            self.detection_model.to(self.device)
            self.detection_model.eval()
            logger.info("âœ… YOLOv5æ¨¡å‹åŠ è½½å®Œæˆ")
        except Exception as e:
            logger.warning(f"YOLOv5åŠ è½½å¤±è´¥: {e}")
            self.detection_model = None

    def setup_transforms(self):
        """è®¾ç½®å›¾åƒå˜æ¢"""
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
        ])

    def calculate_brightness(self, frame: np.ndarray) -> float:
        """è®¡ç®—å¸§çš„äº®åº¦"""
        if len(frame.shape) == 3:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        else:
            gray = frame
        return np.mean(gray)

    def calculate_sharpness(self, frame: np.ndarray) -> float:
        """è®¡ç®—å¸§çš„æ¸…æ™°åº¦ï¼ˆä½¿ç”¨æ‹‰æ™®æ‹‰æ–¯æ–¹å·®ï¼‰"""
        if len(frame.shape) == 3:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        else:
            gray = frame
        return cv2.Laplacian(gray, cv2.CV_64F).var()

    def calculate_motion(self, current_frame: np.ndarray) -> float:
        """è®¡ç®—ä¸å‰ä¸€å¸§çš„è¿åŠ¨é‡"""
        if not self.frame_buffer:
            self.frame_buffer.append(current_frame)
            return 0.0

        # ä¸ç¼“å†²åŒºä¸­çš„å‰ä¸€å¸§æ¯”è¾ƒ
        prev_frame = self.frame_buffer[-1]

        # è½¬æ¢ä¸ºç°åº¦å›¾
        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)
        curr_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)

        # è®¡ç®—å…‰æµæˆ–å¸§å·®å¼‚
        diff = cv2.absdiff(prev_gray, curr_gray)
        motion_score = np.mean(diff) / 255.0

        self.frame_buffer.append(current_frame)
        return motion_score

    def detect_ui_elements(self, frame: np.ndarray) -> bool:
        """æ£€æµ‹UIå…ƒç´  - ç®€åŒ–ç‰ˆæœ¬ï¼Œåªæ£€æµ‹æ˜¾è‘—UI"""
        if self.detection_model is None:
            return False

        try:
            results = self.detection_model(frame)
            detections = results.xyxy[0].cpu().numpy()

            h, w = frame.shape[:2]
            ui_count = 0

            for det in detections:
                x1, y1, x2, y2, conf, cls = det
                if conf > 0.7:  # æé«˜ç½®ä¿¡åº¦é˜ˆå€¼
                    # æ£€æŸ¥æ˜¯å¦åœ¨è¾¹ç¼˜åŒºåŸŸä¸”å°ºå¯¸è¾ƒå¤§
                    if (x1 < 0.1 * w or x2 > 0.9 * w or y1 < 0.1 * h or y2 > 0.9 * h):
                        area = (x2 - x1) * (y2 - y1)
                        if area > (w * h * 0.1):  # é¢ç§¯å¤§äºç”»é¢10%
                            ui_count += 1
                            if ui_count >= 1:
                                return True
        except Exception as e:
            logger.warning(f"UIæ£€æµ‹å¤±è´¥: {e}")

        return False

    def is_good_frame(self, frame: np.ndarray, frame_count: int) -> Tuple[bool, List[str]]:
        """åˆ¤æ–­å¸§æ˜¯å¦ä¸ºå¥½å¸§ - æå¤§æ”¾å®½æ¡ä»¶"""
        reasons = []
        is_good = True

        # 1. æ£€æŸ¥äº®åº¦ - æå¤§æ”¾å®½
        brightness = self.calculate_brightness(frame)
        if brightness < self.brightness_threshold:
            reasons.append(f'äº®åº¦ä¸è¶³: {brightness:.1f}')
            is_good = False

        # 2. æ£€æŸ¥æ¸…æ™°åº¦ - æå¤§æ”¾å®½
        sharpness = self.calculate_sharpness(frame)
        if sharpness < self.sharpness_threshold:
            reasons.append(f'æ¸…æ™°åº¦ä¸è¶³: {sharpness:.1f}')
            is_good = False

        # 3. æ£€æŸ¥è¿åŠ¨ - æå¤§æ”¾å®½
        motion = self.calculate_motion(frame)
        if motion < self.motion_threshold and frame_count > 0:
            reasons.append(f'è¿åŠ¨ä¸è¶³: {motion:.4f}')
            is_good = False

        # 4. æ£€æŸ¥UIå…ƒç´  - åªæ£€æµ‹æ˜¾è‘—UI
        has_ui = self.detect_ui_elements(frame)
        if has_ui:
            reasons.append('æ£€æµ‹åˆ°æ˜¾è‘—UI')
            is_good = False

        return is_good, reasons

    def frame_to_time(self, frame_number: int, fps: float) -> str:
        """å°†å¸§æ•°è½¬æ¢ä¸ºæ—¶é—´æ ¼å¼"""
        total_seconds = frame_number / fps
        hours = int(total_seconds // 3600)
        minutes = int((total_seconds % 3600) // 60)
        seconds = total_seconds % 60
        return f"{hours:02d}:{minutes:02d}:{seconds:06.3f}"

    def log_segment_details(self, segment: Dict, fps: float, segment_id: int, end_reason: str):
        """è®°å½•åˆ†æ®µè¯¦ç»†ä¿¡æ¯"""
        start_time_str = self.frame_to_time(segment['start_frame'], fps)
        end_time_str = self.frame_to_time(segment['end_frame'], fps)

        logger.info("ğŸ¬" + "=" * 60)
        logger.info(f"ğŸ“Š åˆ†æ®µ #{segment_id} è¯¦ç»†ä¿¡æ¯:")
        logger.info(f"  å¼€å§‹å¸§: {segment['start_frame']}")
        logger.info(f"  ç»“æŸå¸§: {segment['end_frame']}")
        logger.info(f"  æ€»å¸§æ•°: {segment['frame_count']}")
        logger.info(f"  å¼€å§‹æ—¶é—´: {start_time_str}")
        logger.info(f"  ç»“æŸæ—¶é—´: {end_time_str}")
        logger.info(f"  æŒç»­æ—¶é—´: {segment['duration']:.2f}ç§’")
        logger.info(f"  åˆ†æ®µåŸå› : {end_reason}")
        logger.info("=" * 60)

    def segment_video(self, video_path: str, output_dir: str,
                      skip_frames: int = 0, max_frames: int = None) -> Dict:
        """åˆ†æ®µå¤„ç†è§†é¢‘ - æŒ‰è¿ç»­å¥½å¸§è¿›è¡Œåˆ†æ®µ"""
        # æ€§èƒ½ç›‘æ§
        start_time = time.time()

        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")

        # è·å–è§†é¢‘ä¿¡æ¯
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        logger.info("ğŸ“¹" + "=" * 60)
        logger.info(f"å¼€å§‹åˆ†æ®µè§†é¢‘: {video_path}")
        logger.info(f"åŸå§‹åˆ†è¾¨ç‡: {width}x{height}")
        logger.info(f"å¸§ç‡: {fps} FPS")
        logger.info(f"æ€»å¸§æ•°: {total_frames}")
        logger.info(f"åˆ†æ®µå‚æ•°: æœ€å°åˆ†æ®µ{self.min_segment_duration}ç§’, æœ€å¤§é—´éš”{self.max_gap_duration}ç§’")
        logger.info("=" * 60)

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)

        # åˆå§‹åŒ–åˆ†æ®µçŠ¶æ€
        segments = []  # å­˜å‚¨åˆ†æ®µä¿¡æ¯: (start_frame, end_frame, frame_count)
        current_segment_frames = []
        gap_frames = 0
        frame_count = 0
        processed_frames = 0

        # ç»Ÿè®¡ä¿¡æ¯
        good_frames_total = 0
        bad_frames_total = 0
        rejection_reasons = {}

        # åˆ†æ®µç»Ÿè®¡
        segment_id = 0
        segment_start_time = None

        # é‡ç½®çŠ¶æ€
        self.frame_buffer.clear()
        self.good_frames_count = 0
        self.bad_frames_count = 0

        while True:
            ret, frame = cap.read()
            if not ret:
                break

            if frame_count < skip_frames:
                frame_count += 1
                continue

            if max_frames and processed_frames >= max_frames:
                break

            # åˆ¤æ–­å¸§è´¨é‡
            is_good, reasons = self.is_good_frame(frame, frame_count)
            processed_frames += 1

            if is_good:
                # å¥½å¸§
                self.good_frames_count += 1
                good_frames_total += 1

                # é‡ç½®åå¸§è®¡æ•°
                gap_frames = 0

                # å¦‚æœæ˜¯æ–°åˆ†æ®µå¼€å§‹
                if not current_segment_frames:
                    segment_start_time = time.time()
                    logger.info(f"ğŸ¬ å¼€å§‹æ–°åˆ†æ®µäºå¸§ {frame_count} (æ—¶é—´: {self.frame_to_time(frame_count, fps)})")

                # æ·»åŠ åˆ°å½“å‰åˆ†æ®µ
                current_segment_frames.append(frame_count)

            else:
                # åå¸§
                self.bad_frames_count += 1
                bad_frames_total += 1

                # è®°å½•æ‹’ç»åŸå› 
                for reason in reasons:
                    rejection_reasons[reason] = rejection_reasons.get(reason, 0) + 1

                # å¦‚æœå½“å‰æœ‰æ´»è·ƒåˆ†æ®µï¼Œå¢åŠ é—´éš”è®¡æ•°
                if current_segment_frames:
                    gap_frames += 1

                    # å¦‚æœé—´éš”è¶…è¿‡é˜ˆå€¼ï¼Œç»“æŸå½“å‰åˆ†æ®µ
                    if gap_frames / fps > self.max_gap_duration:
                        # æ£€æŸ¥åˆ†æ®µé•¿åº¦æ˜¯å¦è¶³å¤Ÿ
                        segment_duration = len(current_segment_frames) / fps
                        if segment_duration >= self.min_segment_duration:
                            segment_id += 1
                            segment_info = {
                                'start_frame': current_segment_frames[0],
                                'end_frame': current_segment_frames[-1],
                                'frame_count': len(current_segment_frames),
                                'duration': segment_duration,
                                'segment_id': segment_id
                            }
                            segments.append(segment_info)

                            # è®°å½•åˆ†æ®µè¯¦ç»†ä¿¡æ¯
                            self.log_segment_details(segment_info, fps, segment_id, "è¿ç»­åå¸§è¶…é˜ˆå€¼")

                        else:
                            segment_processing_time = time.time() - segment_start_time
                            logger.info(
                                f"âŒ åˆ†æ®µè¿‡çŸ­ä¸¢å¼ƒ: {segment_duration:.1f}ç§’, å¤„ç†æ—¶é—´: {segment_processing_time:.1f}ç§’")

                        # é‡ç½®åˆ†æ®µ
                        current_segment_frames = []
                        gap_frames = 0

            frame_count += 1

            if processed_frames % 100 == 0:
                elapsed_time = time.time() - start_time
                fps_processed = processed_frames / elapsed_time
                logger.info(f"â±ï¸ è¿›åº¦: {processed_frames}/{max_frames} å¸§ "
                            f"({processed_frames / total_frames * 100:.1f}%) | "
                            f"å¥½å¸§: {good_frames_total} | åå¸§: {bad_frames_total} | "
                            f"åˆ†æ®µ: {len(segments)} | é€Ÿåº¦: {fps_processed:.1f} FPS")

        # å¤„ç†æœ€åä¸€ä¸ªåˆ†æ®µ
        if current_segment_frames:
            segment_duration = len(current_segment_frames) / fps
            if segment_duration >= self.min_segment_duration:
                segment_id += 1
                segment_info = {
                    'start_frame': current_segment_frames[0],
                    'end_frame': current_segment_frames[-1],
                    'frame_count': len(current_segment_frames),
                    'duration': segment_duration,
                    'segment_id': segment_id
                }
                segments.append(segment_info)

                # è®°å½•åˆ†æ®µè¯¦ç»†ä¿¡æ¯
                self.log_segment_details(segment_info, fps, segment_id, "è§†é¢‘ç»“æŸ")
            else:
                segment_processing_time = time.time() - segment_start_time
                logger.info(f"âŒ æœ€ç»ˆåˆ†æ®µè¿‡çŸ­ä¸¢å¼ƒ: {segment_duration:.1f}ç§’, å¤„ç†æ—¶é—´: {segment_processing_time:.1f}ç§’")

        cap.release()

        # æå–åˆ†æ®µè§†é¢‘
        self._extract_segments(video_path, output_dir, segments, fps, width, height)

        # æ„å»ºç»“æœæ‘˜è¦
        total_time = time.time() - start_time

        results_summary = {
            'video_info': {
                'path': video_path,
                'resolution': f"{width}x{height}",
                'fps': fps,
                'total_frames': total_frames
            },
            'processing_stats': {
                'processed_frames': processed_frames,
                'good_frames': good_frames_total,
                'bad_frames': bad_frames_total,
                'segments_count': len(segments),
                'processing_time': total_time,
                'average_fps': processed_frames / total_time if total_time > 0 else 0,
                'device_used': 'GPU' if torch.cuda.is_available() else 'CPU',
                'good_frame_ratio': good_frames_total / max(processed_frames, 1) * 100
            },
            'segments': segments,
            'rejection_reasons': rejection_reasons
        }

        # ä¿å­˜ç»“æœæ‘˜è¦
        summary_path = os.path.join(output_dir, 'segmentation_summary.json')
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(results_summary, f, indent=2, ensure_ascii=False)

        # æœ€ç»ˆç»Ÿè®¡æ—¥å¿—
        logger.info("ğŸ¯" + "=" * 60)
        logger.info("åˆ†æ®µå¤„ç†å®Œæˆ!")
        logger.info(f"ğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        logger.info(f"  æ€»å¤„ç†å¸§æ•°: {processed_frames}")
        logger.info(f"  å¥½å¸§æ•°é‡: {good_frames_total}")
        logger.info(f"  åå¸§æ•°é‡: {bad_frames_total}")
        logger.info(f"  å¥½å¸§æ¯”ä¾‹: {results_summary['processing_stats']['good_frame_ratio']:.1f}%")
        logger.info(f"  æœ‰æ•ˆåˆ†æ®µ: {len(segments)}")
        logger.info(f"  æ€»å¤„ç†æ—¶é—´: {total_time:.1f}ç§’")
        logger.info(f"  å¹³å‡å¤„ç†é€Ÿåº¦: {results_summary['processing_stats']['average_fps']:.1f} FPS")
        logger.info("=" * 60)

        return results_summary

    def _extract_segments(self, video_path: str, output_dir: str,
                          segments: List[Dict], fps: float,
                          width: int, height: int):
        """æå–åˆ†æ®µè§†é¢‘"""
        logger.info("ğŸ’¾ å¼€å§‹æå–åˆ†æ®µè§†é¢‘...")

        for i, segment in enumerate(segments):
            output_path = os.path.join(output_dir, f"segment_{segment['segment_id']:03d}.mp4")

            # è®¾ç½®è§†é¢‘å†™å…¥å™¨
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

            # è¯»å–å¹¶å†™å…¥åˆ†æ®µ
            cap = cv2.VideoCapture(video_path)
            cap.set(cv2.CAP_PROP_POS_FRAMES, segment['start_frame'])

            frames_written = 0
            segment_extract_start = time.time()

            while frames_written < segment['frame_count']:
                ret, frame = cap.read()
                if not ret:
                    break
                out.write(frame)
                frames_written += 1

            cap.release()
            out.release()

            extract_time = time.time() - segment_extract_start

            logger.info(f"ğŸ“¹ åˆ†æ®µ {segment['segment_id']} å·²ä¿å­˜: {output_path}")
            logger.info(f"   å¸§èŒƒå›´: {segment['start_frame']}-{segment['end_frame']}")
            logger.info(f"   å¸§æ•°é‡: {frames_written}")
            logger.info(f"   æŒç»­æ—¶é—´: {segment['duration']:.2f}ç§’")
            logger.info(f"   æå–æ—¶é—´: {extract_time:.2f}ç§’")


def main():
    """ä¸»å‡½æ•°"""
    # è®°å½•ç¨‹åºå¼€å§‹æ—¶é—´
    program_start = time.time()
    logger.info("ğŸš€ è§†é¢‘åˆ†æ®µç¨‹åºå¯åŠ¨")
    logger.info(f"ğŸ•’ å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    segmenter = GameVideoSegmenter()

    # é…ç½®å‚æ•°
    video_path = "2025-11-22 09-04-51.mp4"  # è¾“å…¥è§†é¢‘è·¯å¾„
    output_dir = "video_segments"  # è¾“å‡ºç›®å½•
    skip_frames = 0  # è·³è¿‡çš„å¸§æ•°
    max_frames = 10800  # æœ€å¤§å¤„ç†å¸§æ•°

    # åˆ†æ®µè§†é¢‘
    results = segmenter.segment_video(
        video_path=video_path,
        output_dir=output_dir,
        skip_frames=skip_frames,
        max_frames=max_frames
    )

    # æ‰“å°æ‘˜è¦
    program_duration = time.time() - program_start

    print("\n" + "=" * 60)
    print("è§†é¢‘åˆ†æ®µç»“æœæ‘˜è¦")
    print("=" * 60)
    print(f"è¾“å…¥è§†é¢‘: {results['video_info']['path']}")
    print(f"è§†é¢‘ä¿¡æ¯: {results['video_info']['resolution']}, {results['video_info']['fps']} FPS")
    print(f"ä½¿ç”¨è®¾å¤‡: {results['processing_stats']['device_used']}")
    print(f"å¤„ç†å¸§æ•°: {results['processing_stats']['processed_frames']}")
    print(f"å¥½å¸§æ•°é‡: {results['processing_stats']['good_frames']}")
    print(f"åå¸§æ•°é‡: {results['processing_stats']['bad_frames']}")
    print(f"å¥½å¸§æ¯”ä¾‹: {results['processing_stats']['good_frame_ratio']:.1f}%")
    print(f"åˆ†æ®µæ•°é‡: {results['processing_stats']['segments_count']}")
    print(f"å¤„ç†æ—¶é—´: {results['processing_stats']['processing_time']:.1f}ç§’")
    print(f"å¤„ç†é€Ÿåº¦: {results['processing_stats']['average_fps']:.1f} FPS")
    print(f"ç¨‹åºæ€»è¿è¡Œæ—¶é—´: {program_duration:.1f}ç§’")

    print(f"\nåˆ†æ®µè¯¦æƒ…:")
    for i, segment in enumerate(results['segments']):
        start_time = segment['start_frame'] / results['video_info']['fps']
        end_time = segment['end_frame'] / results['video_info']['fps']
        print(f"  ğŸ¬ åˆ†æ®µ{segment['segment_id']}: "
              f"å¸§{segment['start_frame']}-{segment['end_frame']} "
              f"({segment['frame_count']}å¸§, {segment['duration']:.1f}ç§’) "
              f"æ—¶é—´[{start_time:.1f}s-{end_time:.1f}s]")

    if results['rejection_reasons']:
        print(f"\næ‹’ç»åŸå› ç»Ÿè®¡:")
        for reason, count in sorted(results['rejection_reasons'].items(), key=lambda x: x[1], reverse=True):
            print(f"  âŒ {reason}: {count}æ¬¡")

    print("=" * 60)

    # è®°å½•ç¨‹åºç»“æŸ
    logger.info(f"ğŸ ç¨‹åºç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"â±ï¸ ç¨‹åºæ€»è¿è¡Œæ—¶é—´: {program_duration:.1f}ç§’")


if __name__ == "__main__":
    main()